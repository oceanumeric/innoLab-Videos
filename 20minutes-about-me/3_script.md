Hello everyone,

This is the second video of the series '20 minutes about me'. In this video, I will share my experiences about data science and deep learning.

As I have explained that I am doing this is to let potential collaborators, investors, and recruiters know more about me. I believe it is important to know a person's value, expertise, and vision before deciding to work together.


The theme of this video is about data science and deep learning. This video is relative short as I assume you have some basic knowledge about these topics. Therefore, I will just mention some key points.


If you look at the image on the right, data science is usually defined as a intersection of math&statistics, domain knowledge, and programming. I will follow this order to show my expertise in data science.


First, it is about math and statistics. To understand my strength in this field, I suggest you to check my website where I have published some post about math and statistics. I have also got a degree in math from University Colledge Dublin with the first class honor.


Now, let's move to domain knowledge. From 2011 to 2016, I worked as financial analyst in an alternative investment company. During this period, I mainly use R to do time series analysis and financial modeling. I also use SQL to extract data from database. I have also got a CFA charterholder.


From 2016 to 2019, I studied in the UK and Germany, gained experience in econometric modeling and machine learning. I have also got a master degree in economics from University of Nottingham.

From 2019 to 2021, I worked as a machine learning engineer in an AI company called SenseTime. I mainly work on common machine learning tasks, such as classification, regression, and clustering. At that time, I gained experience on development operation and software engineering as I have to ship some in-house tools to python package.


From 2021 to 2024, I worked as a research assistant in Goethe University Frankfurt. I mainly work on NLP and knowledge graph. I have recorded another video to explain this part.


This image shows my certification of being a CFA charterholder.


For the programming skill, the best place to check is my github. I put my github link at the end of this video. You can check my code and see if I am a good fit for your project.


Now, let's move to programming. Because most of my work are data-driven. For table-like data, I use R, Python and SQL. With R programming, I am an expert of data.table package. With Python, I am an expert of pandas and numpy. With SQL, I am an expert of MySQL, PostgreSQL, and SQLite, and more recently, duckdb.

When it comes to text data or NLP task, Those are packages I use most frequently. For data engineer, I mainly use GUN make and docker. 


Let's move to the next part - statiscal modeling. Here I give three books that I most frequently use. The first one is 'Elements of Statistical Learning'. The second one is 'Probailistic Machine Learning', and the last is staistical rethinking. 


Let's move to the last part - deep learning. Again, I will only put some tools that I am familiar with and some books I have studied and practiced. 


Okay, that's all for this video. I hope enjoyed this video. Because I only briefly mentioned some key points. I could refer you to my website and my github for more details. Of course, you can also contact me directly. I am happy to discuss with you.

